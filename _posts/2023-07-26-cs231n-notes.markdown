---
layout: post
title: 'Notes for CS231n'
date: '2023-07-26 22:00:00'
---

## Image Classification 

- challenges: scale, deformation, occulsion, lighting, background

data-driven approach >> hardcoding an algorithm to recognizing an object

### image classification pipeline

> input -> learning -> evaluation

### nearest neighbor classifier

L1 distance -> 38.6% accuracy
L2 distance -> 35.4% accuracy

![L1](/assets/L1.jpg)

L1 vs L2 - L2 is more tighter in scoring the difference between two vectors. special subset of p-norm


#### k-nearest neighbor classifier

instead of finding the single closest image in the training set, we will find the top k closest images, and have them vote on the label of the test image. 

![knn](/assets/knn.jpg)

k=1 is essentially the basic "nearest neighbor classifier". 

k is a hyperparameter. 
hyperparameters should be configured through cross-validation (i.e. picking an arbitrary small percentage of the training data to tune which hyperparameters work best)

![folds](/assets/folds.jpg)

5-fold cross-validation - 4 for training 1 for validation

more hyperparameters bigger validation splits

cons - cheap to train but more expensive to test

useful when data is low dimensional. 
